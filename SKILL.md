---
name: patient-accumulation-method
description: Gather comprehensive evidence from diverse sources before drawing conclusions.
  Resist the urge to theorize prematurely—let patterns emerge from thorough, systematic
  observation.
license: MIT
metadata:
  version: 1.0.0
  author: sethmblack
keywords:
- patient-accumulation-method
- writing
---

# Patient Accumulation Method

Gather comprehensive evidence from diverse sources before drawing conclusions. Resist the urge to theorize prematurely—let patterns emerge from thorough, systematic observation.

---

## When to Use

- Facing complex questions with no obvious answer
- Suspecting that quick conclusions would be premature
- User asks "What does the evidence really show?" or "Build the full picture"
- Need to establish a robust foundation before acting
- Existing consensus seems inadequately supported
- High-stakes decisions requiring thorough analysis

---

## Inputs

| Input | Required | Description |
|-------|----------|-------------|
| question | Yes | The question or hypothesis to investigate |
| known_sources | No | Evidence sources already identified |
| constraints | No | Time or resource limits for investigation |

---

## Darwin's Principle

"It occurred to me, in 1837, that something might perhaps be made out on this question by patiently accumulating and reflecting on all sorts of facts which could possibly have any bearing on it."

Darwin spent over 20 years gathering evidence before publishing the Origin. He corresponded with hundreds of naturalists, breeders, and experts. He studied barnacles for eight years. He collected observations from multiple continents. Only after this patient accumulation did he allow himself to draw conclusions publicly.

The method is not mere caution—it produces qualitatively better understanding. Patterns visible only across comprehensive evidence remain invisible to the quick theorist.

---

## The Patient Accumulation Framework

### Step 1: Frame the Question Precisely

Before gathering evidence, clarify exactly what you're investigating:

**Question formulation:**
- What exactly am I trying to understand?
- What would count as an answer?
- What distinguishes this question from adjacent ones?

**Scope definition:**
- What is included in the inquiry?
- What is explicitly excluded?
- What time period is relevant?

**Key sub-questions:**
- What component questions make up the main question?
- What would I need to know to answer each?

### Step 2: Map the Evidence Landscape

Identify all potential sources of relevant evidence:

**Direct sources:**
- Primary observations you can make
- Data you can collect or access
- Experiments you can conduct

**Indirect sources:**
- Existing research and literature
- Expert knowledge (who would know?)
- Analogous cases that might inform

**Diverse perspectives:**
- Who sees this differently?
- What adjacent domains have relevant evidence?
- What would skeptics point to?

### Step 3: Gather Systematically

Collect evidence with discipline and breadth:

**Breadth before depth:**
- Survey widely before diving deep on any single source
- Resist the pull of early compelling evidence
- Continue gathering even when a pattern seems to emerge

**Documentation discipline:**
- Record sources and confidence levels
- Note uncertainties and gaps
- Track what you expected vs. what you found

**Actively seek disconfirming evidence:**
- What would suggest my emerging view is wrong?
- Who disagrees, and what do they point to?
- What cases don't fit the pattern?

### Step 4: Reflect on Patterns

After sufficient accumulation, step back and observe:

**Pattern identification:**
- What themes emerge across sources?
- What correlations appear?
- What exceptions exist, and why?

**Confidence weighting:**
- Where is evidence strong vs. weak?
- What would increase confidence?
- What remains genuinely uncertain?

**Synthesis:**
- What story do the facts tell together?
- What conclusion is best supported?
- What alternative interpretations remain viable?

### Step 5: State Conclusions with Appropriate Confidence

Draw conclusions that reflect the evidence quality:

**Confidence levels:**
- "The evidence strongly suggests..." (high confidence)
- "The evidence is consistent with..." (moderate confidence)
- "Insufficient evidence to conclude..." (honest uncertainty)

**Remaining questions:**
- What do you still not know?
- What additional evidence would help?
- What are the key uncertainties?

---

## Workflow

### Step 1: Gather and Review Inputs

Collect all relevant information:
- Review the provided data and context
- Identify key parameters and constraints
- Clarify any ambiguities or missing information
- Establish success criteria

### Step 2: Analyze the Situation

Perform systematic analysis:
- Identify patterns and relationships
- Evaluate against established frameworks
- Consider multiple perspectives
- Document key findings

### Step 3: Generate Recommendations

Create actionable outputs:
- Synthesize insights from analysis
- Prioritize recommendations by impact
- Ensure recommendations are specific and measurable
- Consider implementation feasibility

## Output Format

```markdown
## Patient Accumulation Analysis: [Question]

### Question Framed
[Precise statement of what's being investigated]

**Scope:** [What's included and excluded]

**Sub-questions:**
1. [Sub-question 1]
2. [Sub-question 2]
3. [Sub-question 3]

### Evidence Sources Surveyed

| Source Type | Sources Consulted | Key Findings | Confidence |
|-------------|-------------------|--------------|------------|
| [Direct observation] | [Specific sources] | [What they show] | [High/Med/Low] |
| [Literature/research] | [Sources] | [Findings] | [Confidence] |
| [Expert knowledge] | [Who] | [What they say] | [Confidence] |
| [Analogous cases] | [Cases] | [What they suggest] | [Confidence] |

### Evidence Summary

**Consistent with conclusion:**
1. [Evidence 1] - Source: [X], Confidence: [Y]
2. [Evidence 2] - Source: [X], Confidence: [Y]

**Inconsistent or challenging:**
1. [Counter-evidence 1] - [How addressed]
2. [Counter-evidence 2] - [How addressed]

**Gaps in evidence:**
1. [What's not known]
2. [What couldn't be accessed]

### Pattern Analysis

**Primary patterns observed:**
- [Pattern 1 across multiple sources]
- [Pattern 2 across multiple sources]

**Notable exceptions:**
- [Exception 1] - Possible explanation: [X]
- [Exception 2] - Possible explanation: [X]

### Conclusions

**Main conclusion:** [Statement with confidence level]
Evidence strength: [Strong/Moderate/Weak]
Confidence: [High/Medium/Low]

**Alternative interpretations:**
- [Alternative 1] - Why less likely: [X]
- [Alternative 2] - Why less likely: [X]

**Remaining uncertainties:**
- [Key uncertainty 1]
- [Key uncertainty 2]

### Recommendations for Further Investigation
[What additional evidence would strengthen conclusions]
```

---

## Evidence Quality Standards

### Strong Evidence
- Multiple independent sources converge
- Direct observation or measurement
- Replicable or verifiable
- No obvious bias or conflict of interest

### Moderate Evidence
- Limited sources, but credible
- Indirect but logical inference
- Some uncertainty but reasonable
- Minor potential biases acknowledged

### Weak Evidence
- Single source or anecdotal
- High potential for bias
- Inference chain is long
- Significant uncertainties

### Disqualified Evidence
- Circular reasoning
- Unfalsifiable claims
- Known bias without correction
- Speculation presented as fact

---

## Constraints

- This method requires time—not suitable for urgent decisions
- Diminishing returns eventually set in; perfection is impossible
- Must eventually conclude, even with imperfect evidence
- Beware analysis paralysis disguised as thoroughness
- Some questions cannot be answered with currently available evidence

---

## Outputs

**Primary Output:** A structured analysis document that identifies and articulates patterns, insights, and actionable recommendations based on the input data.

**Format:**
```markdown
## Analysis: [Topic]

### Key Findings
- [Finding 1]
- [Finding 2]
- [Finding 3]

### Recommendations
1. [Action 1]
2. [Action 2]
3. [Action 3]
```

**Example output:** See the Example section below for a complete demonstration.

## Example

**Input:** "Should we expand into the European market?"

**Output:**



**Why this works:**

This example demonstrates the key principles of the skill in action. The approach is effective because:
- It follows the systematic workflow outlined above
- It shows concrete application of the framework
- It produces actionable, specific outputs rather than vague generalizations
- The analysis is grounded in observable details
- The recommendations are prioritized and implementable

**Alternative applications:**

This same approach can be applied to:
- Different contexts within the same domain
- Related but distinct problem types
- Scaled up or down depending on scope
- Combined with complementary analytical frameworks


## Patient Accumulation Analysis: European Market Expansion

### Question Framed
Should our company (B2B SaaS, $15M ARR, US-based) expand into the European market in the next 12 months?

**Scope:** Focus on Western Europe (UK, Germany, France, Netherlands, Nordics). Exclude Eastern Europe for now. Consider revenue opportunity, operational requirements, competitive dynamics, and strategic fit.

**Sub-questions:**
1. What is the addressable market opportunity in target countries?
2. What would expansion require operationally?
3. What competitive dynamics exist in those markets?
4. How does this fit our current strategy and capacity?
5. What do similar companies' European expansions teach us?

### Evidence Sources Surveyed

| Source Type | Sources Consulted | Key Findings | Confidence |
|-------------|-------------------|--------------|------------|
| Market research | Gartner, Forrester, local reports | TAM ~$400M in our category across target markets | Medium |
| Internal data | Existing EU inbound leads, trial signups | 12% of trials from EU, 4% of revenue | High |
| Customer interviews | 8 existing EU customers, 5 prospects | Willing to pay, want local support and GDPR compliance | Medium |
| Competitor analysis | 3 US competitors' EU operations | All entered via UK first, mixed results | Medium |
| Expert interviews | 2 consultants, 1 former competitor exec | Estimate 18-24 months to profitability in EU | Medium |
| Analogous cases | 5 similar-stage SaaS EU expansions | 3 succeeded (eventually), 2 pulled back | Low-Medium |
| Operational research | Legal, compliance, HR requirements | GDPR compliance ~$150K, entity setup ~$50K, hiring ~$200K/year | High |

### Evidence Summary

**Consistent with expansion:**
1. Genuine market demand—12% of trials from EU despite no marketing there - Confidence: High
2. Existing customers validate product-market fit - Confidence: Medium
3. Competitors have established presence (market is real) - Confidence: High
4. TAM estimates support meaningful revenue opportunity - Confidence: Medium

**Inconsistent or challenging:**
1. Conversion rate EU trials to paid significantly lower (2.1% vs 5.4% US) - Suggests friction/fit issues
2. Competitor exec warned "took 3x longer and 2x cost than planned" - Single source but experienced
3. Current team has no EU operational experience - Execution risk
4. EUR/USD volatility adds financial complexity - Moderate concern

**Gaps in evidence:**
1. No direct competitive win/loss data in EU
2. Unknown: regulatory changes pending that might affect market
3. Limited data on country-specific differences (treated EU as monolith)

### Pattern Analysis

**Primary patterns observed:**
- Demand exists but conversion barriers are real (consistent across trial data, customer interviews)
- Operational complexity underestimated by most (all 5 analogous cases, expert interviews)
- UK-first is standard playbook, often followed by Germany
- 18-24 month timeline to meaningful revenue is realistic

**Notable exceptions:**
- One analogous company (similar size, adjacent category) achieved profitability in 14 months—differentiator was hiring experienced EU GM before launch
- One existing EU customer drives 3x ACV of US average—suggests potential for larger deals if properly pursued

### Conclusions

**Main conclusion:** Market opportunity is real, but company is not ready to execute well on EU expansion in next 12 months. Recommend a 12-month preparation period followed by deliberate UK-first entry.

Evidence strength: Moderate
Confidence: Medium-High

**Reasoning:**
- Demand signal is genuine (strong evidence)
- Conversion gap indicates product/go-to-market issues to solve first (strong evidence)
- Operational complexity is consistently underestimated (strong pattern)
- Success cases had EU-experienced leadership in place first (pattern from cases)

**Alternative interpretations:**
- "Move now, learn fast" - Why less likely: Operational evidence suggests "fast" is ~2 years anyway; better to prepare
- "EU not worth it, focus US" - Why less likely: 12% trial share indicates real demand leaving money on table
- "Start with Germany not UK" - Why less likely: UK offers language advantage, UK customers easier to learn from

**Remaining uncertainties:**
- Whether conversion gap is fixable (product issue vs. market difference)
- Brexit long-term effects on UK as EU entry point
- Competitive response if we delay
- Ability to hire EU-experienced GM

### Recommendations for Further Investigation
1. Deep-dive on EU trial conversion dropoff points (product analytics)
2. 10 more customer interviews focused on conversion blockers
3. Identify and interview 3-5 potential EU GM candidates (even to learn)
4. Country-specific analysis (UK vs. Germany vs. Netherlands as entry)
5. Monitor for regulatory changes through Q2

*"I worked on true Baconian principles, and without any theory collected facts on a wholesale scale."* A decision this significant deserves the same treatment Darwin gave to questions that would change the world.

---

## Integration

This skill is part of the **Charles Darwin** expert persona. Use it when the stakes are high enough to warrant thorough investigation, or when you suspect that quick conclusions are masking important complexity. Pairs with:
- **variation-mapping** to understand what varies within the evidence
- **severe-test-protocol** to test emerging conclusions
- **analogical-bridge** to draw lessons from similar cases